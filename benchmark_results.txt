/Users/user/Hands-on/hcx-seed-think-32b-knowledge-injection/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(

[1/3] Loading Base Model...
--- Base Model Inference ---
Prompt: What is CLaRa?
Response: CLaRa is a classroom audio system that is designed to improve the listening experience for teachers and students. It is a wireless system that uses Bluetooth technology to connect to a teacher's device, such as a laptop or tablet, and transmit the audio to speakers placed in the classroom. CLaRa is designed to be easy to set up and use, and it can be used in a variety of classroom settings.
Stats: 5.16s, 15.88 t/s
--- Base Model Inference ---
Prompt: What is SCP in CLaRa?
Response: In CLaRa, SCP stands for Secure Copy Protocol. It is a protocol used to transfer files between the server and the client. SCP is implemented in the scp module, which is a part of the CLaRa package. The scp module provides a secure and efficient way to transfer files over the network.
Stats: 3.94s, 15.74 t/s
--- Base Model Inference ---
Prompt: Explain the joint training in CLaRa.
Response: In CLaRa, the joint training refers to the process of training both the controller and the model simultaneously. This is done to improve the performance of the model and the controller. The joint training is performed by minimizing the loss function, which is a combination of the loss function of the model and the loss function of the controller. The joint training is performed for a certain number of epochs, and the model and the controller are updated simultaneously. The joint training is an important step in CLaRa,
Stats: 6.14s, 16.28 t/s

[2/3] Loading CPT Model...
--- CPT Model Inference ---
Prompt: What is CLaRa?
Response: CLaRa is a name given to a 1984-1986 Chevrolet El Camino that was equipped with a 454 cubic-inch (7.5L) V8 engine and a 4-speed manual transmission. The name "CLaRa" is an acronym for "Chevrolet, 454, El Camino, Redline."
Stats: 5.07s, 15.39 t/s
--- CPT Model Inference ---
Prompt: What is SCP in CLaRa?
Response: In the context of the CLaRa model, SCP stands for Self-optimizing Presenter. It is a key component of the model that is responsible for dynamically adjusting the presentation of information to the teacher. The SCP module analyzes the teacher’s feedback and the performance of the system, and then optimizes the presentation strategy accordingly. This self-optimization allows the model to adapt to the teacher’s preferences and improve the overall learning experience.
Stats: 5.67s, 15.86 t/s
--- CPT Model Inference ---
Prompt: Explain the joint training in CLaRa.
Response: The joint training in CLaRa is a joint training of the generator and discriminator. The generator generates a latent variable z from the input x and reconstructs it as a reconstructed output x'. The discriminator takes the input x and outputs a scalar value D. The generator and discriminator are jointly trained using the following loss function: L = L_recon + λL_cls where L_recon is the reconstruction loss and L_cls is the classification loss. The reconstruction loss is defined as: L_recon
Stats: 6.14s, 16.28 t/s

[3/3] Loading SFT Model...
--- SFT Model Inference ---
Prompt: What is CLaRa?
Response: CLaRa stands for Continuous Latent Reasoning. It is a retrieval-augmented language model that performs continuous reasoning via a differentiable language-to-language (L2L) framework. It uses a differentiable language-to-language (L2L) framework to perform continuous reasoning, which allows it to perform complex reasoning tasks that traditional language models cannot.
Stats: 4.54s, 15.65 t/s
--- SFT Model Inference ---
Prompt: What is SCP in CLaRa?
Response: SCP stands for Salient Compressor Pretraining. It is a key training stage in CLaRa, the Continuous Latent Reasoning framework. It trains the compressor to represent the salient information in the data.
Stats: 2.88s, 14.94 t/s
--- SFT Model Inference ---
Prompt: Explain the joint training in CLaRa.
Response: CLaRa stands for Continuous Latent Reasoning and Reasoning. It trains the generator and the reasoning model end-to-end via a single data synthesis and reasoning loop. It trains the generator and the reasoning model end-to-end via a single data synthesis and reasoning loop. It trains the generator and the reasoning model end-to-end via a single data synthesis and reasoning loop. It trains the generator and the reasoning model end-to-end via a single data synthesis and reasoning loop. It trains the generator and the
Stats: 6.04s, 16.56 t/s


=== Benchmark Summary ===
Model           | Query                          | Tokens/s   | Response Start
--------------------------------------------------------------------------------
Base Model      | What is CLaRa?                 | 15.88      | CLaRa is a classroom audio system that i...
Base Model      | What is SCP in CLaRa?          | 15.74      | In CLaRa, SCP stands for Secure Copy Pro...
Base Model      | Explain the joint training in  | 16.28      | In CLaRa, the joint training refers to t...
CPT Model       | What is CLaRa?                 | 15.39      | CLaRa is a name given to a 1984-1986 Che...
CPT Model       | What is SCP in CLaRa?          | 15.86      | In the context of the CLaRa model, SCP s...
CPT Model       | Explain the joint training in  | 16.28      | The joint training in CLaRa is a joint t...
SFT Model       | What is CLaRa?                 | 15.65      | CLaRa stands for Continuous Latent Reaso...
SFT Model       | What is SCP in CLaRa?          | 14.94      | SCP stands for Salient Compressor Pretra...
SFT Model       | Explain the joint training in  | 16.56      | CLaRa stands for Continuous Latent Reaso...
